\documentclass[12pt]{article}

\usepackage{sbc-template}

\usepackage[brazil]{babel}   
%\usepackage[latin1]{inputenc}  
\usepackage[utf8]{inputenc}  
% UTF-8 encoding is recommended by ShareLaTex

\usepackage{hyperref}
\usepackage{mdframed}
\usepackage{minted}

\sloppy

\title{Trabalho Prático 2 - Processamento de Linguagem Natural}

\author{Hugo Araujo de Sousa}

\address{
  Processamento de Linguagem Natural (2017/2) \\
  Departamento de Ciência da Computação \\
  Universidade Federal de Minas Gerais (UFMG)
  \email{hugosousa@dcc.ufmg.br}
}

\begin{document} 

\maketitle
     
\begin{resumo} 
  O objetivo desse trabalho é estudar a tarefa de Part-of-Speech (POS) tagging
  para a Língua Portuguesa. Para isso, utilizamos o corpus Mac-Morpho e comparamos
  o desempenho de dois modelos preditivos, um paramétrico e outro não-paramétrico.
\end{resumo}

\section{INTRODUÇÃO}

Em Processamento de Linguagem Natural, uma vez que o principal objetivo é fazer
com que os computadores entendam as linguagens naturais usadas pelos seres
humanos, muitas vezes torna-se necessário reduzir a complexidade dessa tarefa
ao quebrá-la em tarefas intermediárias. Uma dessas tarefas, que é particularmente
útil na área de \textbf{parsing}, é a tarefa de \textbf{Part-of-speech tagging},
que se trata da identificação das classes gramaticais de cada uma das palavras
presentes um corpus \cite{Manning:1999:FSN:311445}. Esse problema não trata-se
apenas da criação de um banco de dados que contenha a classe de cada palavra,
uma vez que uma mesma palavra pode estar associada a múltiplas classes de acordo
com seu contexto e posição em uma sentença.

Uma das abordagens que podem usadas para resolver esse problema é utilizar algum
algoritmo de aprendizado de máquina supervisionado. Nesse trabalho, serão
utilizados dois algoritmos de aprendizado para resolver o problema de POS
tagging a fim de verificar e comparar a precisão e desempenho de cada um.

\section{MODELAGEM}

Dentro dos métodos de aprendizado de máquina supervisionada, existem os 
paramétricos e os não-paramétricos. A diferença entre os dois é que, nos métodos
paramétricos, assume-se que os dados se organizam em algum modelo e então encontra-se
valores apropriados do modelo a partir dos exemplos. Para abordar o problema
de POS tagging, vamos utilizar um algoritmo de cada categoria, sendo
\textbf{Naive Bayes} \cite{McCallum98acomparison} o paramétrico e o classificador
 de \textbf{Support Vector Machines (SVM)} \cite{708428} o não-paramétrico.

Uma vez determinados os algoritmos a serem utilizados no processo de aprendizado,
é necessário discutir o conjunto de dados de entrada e o mapeamento desses dados
para a entrada dos algoritmos.

\subsection{Corpus de Entrada}

O conjunto de dados utilizado no trabalho como entrada dos algoritmos de
aprendizado é o corpus Mac-Morpho \cite{Aluisio2003}. O Mac-Morpho é um corpus
de textos escritos em Português Brasileiro, anotados com as classes gramaticais
de cada palavra presente. Há, disponíveis para download gratuito, as seções
de treinamento, validação e teste do corpus, que representam $ 76\% $, $ 4\% $ e
$ 20\% $ do total do corpus, respectivamente.

Na página do corpus online
\footnote{ \url{http://nilc.icmc.usp.br/macmorpho} } é possível fazer o download
 do mesmo, juntamente com o manual das anotações, que descreve todas as classes gramaticais utilizadas no corpus.

\subsection{Extração de Features}

Com o corpus de entrada em mãos, o próximo passo foi determinar como mapear esses
dados para serem alimentados aos algoritmos de aprendizado de máquina. Para isso,
a decisão foi trabalhar com features das palavras. Essas features são, como o
nome indica, características obtidas através de cada palavra em si, além do seu
contexto na sentença em que se encontra, isto é, posição absoluta e relativa às
classes gramaticais. A lista das features utilizadas no trabalho é mostrada
na Tabela \ref{tab:features}.

\begin{table}[h]
	\centering
	\begin{tabular}{|c|c|}
		\hline
		\textbf{Feature} & \textbf{Descrição} \\ \hline
		\textbf{word} & A própria palavra em si. \\ \hline
		\textbf{is\_first} & Booleano que indica se a palavra é a primeira da sentença. \\ \hline
		\textbf{is\_last} & Booleano que indica se a palavra é a primeira da sentença. \\ \hline
		\textbf{is\_capitalized} & Booleano que indica se a palavra começa com uma letra maiúscula. \\ \hline
		\textbf{is\_all\_caps} & Booleano que indica se a palavra somente contém
		letras maiúsculas. \\ \hline
		\textbf{is\_all\_lower} & Booleano que indica se a palavra contém somente
		letras minúsculas. \\ \hline
		\textbf{prefix-1} & String com o primeiro caractere da palavra. \\ \hline
		\textbf{prefix-2} & String com os dois primeiros caracteres da palavra. \\ \hline
		\textbf{prefix-3} & String com os três primeiros caracteres da palavra. \\ \hline
		\textbf{suffix-1} & String com o último caractere da palavra. \\ \hline
		\textbf{suffix-2} & String com os dois últimos caracteres da palavra. \\ \hline
		\textbf{suffix-3} & String com os três últimos caracteres da palavra. \\ \hline
		\textbf{prev\_tag} & String que representa a classe gramatical da palavra
		anterior à palavra atual. \\ \hline
		\textbf{next\_tag} & String que representa a classe gramatical da palavra
		seguinte à palavra atual. \\ \hline
		\textbf{has\_hyphen} & Booleano que indica se a palavra possui hífen.
		\\ \hline
		\textbf{is\_numeric} & Booleano que indica se a palavra é um número
		(dígitos). \\ \hline
	\end{tabular}
	\caption{\label{tab:features} Features de palavras utilizadas no trabalho.}
\end{table}

\section{IMPLEMENTAÇÃO}

O trabalho foi implementado utilizando a linguagem Python 3. Além disso, nenhum
dos algoritmos de aprendizado de máquina foram implementados, sendo utilizada
uma biblioteca que já continha tanto uma implementação do Naive Bayes quanto do
SVM. Essa biblioteca é a Scikit-Learn
\footnote{\url{http://scikit-learn.org/stable/}}.

\subsection{Decisões de Implementação}

Algumas decisões de implementação foram se mostrando necessárias ao longo do 
desenvolvimento do projeto. Estas são apresentadas a seguir:

\begin{itemize}
	\item \textbf{Feature Hasher:} Para cada palavra do corpus, os features são
	coletados e armazenados em um dicionário. Para usar esses dados como entrada
	dos algoritmos de aprendizado, é necessário efetuar uma transformação para
	uma matriz de tipo Numpy Array \footnote{\url{www.numpy.org/}}. O utilitário 
	FeatureHasher da biblioteca Scikit-Learn se encarrega dessa tarefa, sendo
	muito útil para conjuntos de dados tão grandes como o corpus Mac-Morpho.
	Com ele, a lista que contém os dicionários que representam os features
	de cada palavra são convertidos para Numpy Array de forma eficiente tanto
	em tempo quanto espaço. No momento da instanciação de um objeto FeatureHasher,
	especifica-se o número de features no dicionário de features. No caso desse
	trabalho, esse número é igual a 17.

	\item \textbf{Naive Bayes Gaussiano:} A biblioteca Scikit-Learn fornece várias
	implementações do algoritmo de Naive Bayes. Dentre essas, duas foram testadas
	no trabalho: a implementação Multinomial e a Gaussiana. Comparando a precisão
	obtida com ambas, foi verificado que a segunda atinge maior precisão para o 
	corpus e, portanto, foi usada no código final do projeto.
\end{itemize}

\subsection{Execução do Projeto}

Os arquivos do projeto encontram-se distribuídos em três pastas:

\begin{itemize}
	\item \textbf{doc:} Contém os arquivos de documentação e manual de tags 
	do corpus Mac-Morpho.

	\item \textbf{corpus:} Base de dados do corpus Mac-Morpho, dividido em treino,
	validação e teste.

	\item \textbf{src:} Código fonte do programa principal que lê o corpus, 
	calcula as features de cada palavra e alimenta esses dados aos dois
	algoritmos de aprendizado, imprimindo os resultados de precisão para cada um
	deles.
\end{itemize}

Para executar o programa, na pasta \textbf{src}, basta executar o comando:

\begin{center}
	./tp2.py [-h] [-s RSEED] train\_file test\_file validation\_file
\end{center}

Onde os argumentos do programa são:

\begin{itemize}
	\item \textbf{Argumentos posicionais:}

	\begin{itemize}
		\item train\_file: Nome do arquivo de treino.
		\item test\_file: Nome do arquivo de teste.
		\item validation\_file: Nome do arquivo de validação.
	\end{itemize}

	\item \textbf{Argumentos opcionais:}

	\begin{itemize}
		\item -h ou --help: Exibe uma mensagem de ajuda e termina execução.
		\item -s RSEED: Seta o número RSEED como semente de geração de números
		aleatórios para o algoritmo SVM.
	\end{itemize}
\end{itemize}

\section{RESULTADOS}

Executando o programa com o corpus Mac-Morpho, uma das saídas obtidas (resultado
do SVM varia com o número da seed de números aleatórios) é mostrada a seguir.

\begin{mdframed}[linecolor=black, leftline=false, rightline=false]
    \inputminted[linenos, fontsize=\footnotesize]{text}{../src/out.txt}
\end{mdframed}

Um primeiro resultado interessante a observar é o aspecto de tempo de execução.
Enquanto o Naive Bayes demora cerca de 30 segundos para executar com todos os 
arquivos do corpus Mac-Morpho, o SVM precisa de por volta de 7 horas para computar seus resultados.

Em relação à precisão de acerto dos algoritmos, vemos que as classes mais
difíceis de serem previstas utilizando os mesmo foram as classes Interjeição e
aquelas formadas pela combinação entre Preposições e outras classes gramaticais.
Podemos a baixa acurácia da classe de interjeição a partir do fato de que as
palavras dessa classe, além de geralmente serem muito curtas (sem informação
de sufixos ou prefixos), também geralmente vêm sozinhas em uma frase -
 \textit{"Ufa!"} -, não possuindo assim qualquer informação de contexto. Com
 esses fatores, essas palavras acabam produzindo features pouco expressivos no
 programa. Já para as preposições combinadas com outras classes, uma hipótese
 para tal precisão baixa é a de que padrões mais complicados (que envolvem uma
 sequência de tags) não são de fácil aprendizado para os algoritmos.

Uma outra observação diz respeito à precisão muito próxima de $ 100\% $ para a
classe de Símbolo de Moeda Corrente. Isso muito provavelmente se deve ao fato de
que as palavras dessa classe são identificadas por serem numéricas e, como há
um feature para identificar tal situação, os algoritmos não têm dificuldade em
aprender esse padrão.

\section{CONCLUSÃO}

O trabalho em questão possibilitou um grande aprendizado, além de fixar aquele já adquirido durante as aulas da disciplina de Processamento de Linguagem
Natural.

Dentro do aspecto do conhecimento adquirido com a disciplina, é importante destacar os métodos de aprendizado supervisionado, que aqui ilustram como é
feito o processo de treinamento para uma tarefa da área de Processamento de
Linguagem Natural. Foi muito interessante utilizar dois modelos, um paramétrico
e outro não-paramétrico, obter seus resultados e poder compará-los a fim de
 verificar os padrões identificados por cada um e como o fato de serem
 paramétricos ou não afetam nesses padrões e resultados, buscando encontrar
 explicações para os mesmos.

Finalmente, ressalto a utilidade do trabalho para poder adquirir conhecimento
sobre a biblioteca Scikit-Learn e sobre o corpus Mac-Morpho, creio que esses
dois conhecimentos são de grande importância para qualquer estudante da área.

\section{REFERÊNCIAS}

\bibliographystyle{sbc}
\bibliography{sbc-template}

\end{document}
